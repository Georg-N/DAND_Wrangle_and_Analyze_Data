{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of this project is to put into practice the learnings of the data wrangling part of the data analyst nanodegree of udacity. The dataset that I was wrangling is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though are almost always greater than 10 (e.g. 13/10).\n",
    "\n",
    "The tasks of the wrangling process included the following:\n",
    "Gathering data\n",
    "Assessing data\n",
    "Cleaning data\n",
    "\n",
    "## Gathering Data\n",
    "Three data sets were used in this project. They were gathered as follows:\n",
    "1. Twitter archive file: the twitter_archive_enhanced.csv was provided by Udacity\n",
    "2. Tweet image predictions: this data contains predictions with methods of machine learning for the breed of the dog of each tweet's image. This file is accessable by an internet link that was provided by Udacity.\n",
    "3. Twitter json file: This is the resulting data which Udacity gathered by using the twitter API. It is a .txt file in json script. I read this tweet_json.txt file line by line into a pandas DataFrame with tweet ID, retweet count, and favorite count.\n",
    "\n",
    "## Assessing Data\n",
    "Once I was finished with gathering I assessed the data visually as well as programmatically. For visual assessment I displayed the data frames in the Jupyter Notebook. For the programmatic assessment I used various methods from python specifically from the pandas library. I separated my findings into quality and tidiness issues.\n",
    "\n",
    "## Cleaning Data\n",
    "This part involved the following three steps for each aspect to be cleaned: Define, Code and Test.\n",
    "\n",
    "First I copied the data frames into cleaning data frames.\n",
    "\n",
    "One part of my cleaning efforts was converting the datatype of certain columns into another data type that can better be worked with. This is especially important for the merging of the three tables, which was also part of my cleaning efforts. If the key does not have the same format the merging of the table does not work properly.\n",
    "\n",
    "Another part was to drop unnecessary columns. This reduces the data to the only necessary amount.\n",
    "\n",
    "A number of numerators of this dataset did not equal to 10. Some of these tweets' texts actually had several elements that qualified for a rating having a number then a slash and a number again. But they were no actual ratings (e.g. mentioning the super market 7/11). As the data set always picked the first element that qualified for a rating some of the ratings were wrong. Therefore, I wrote a function that searched for elements in the text that qualified for ratings and then picked the one that had a numerator closest to ten.\n",
    "\n",
    "Another challenge was that there were denominators that were bigger than 15. Some of the denominators had values with decimals (e.g. 11.26) but in the original data set the 26 was picked as the rating. Therefore I wrote a function that identifies such ratings with decimals and converted it to an integer. Like this the rating data was more accurate.\n",
    "\n",
    "Furthermore, I wrote a melt function that created one columns for the dog stages. I did not use the melt method, as some tweets had multiple dog stages and I didn't find a way the method to account for this. After executing the melt function I dropped the single dog stages columns.\n",
    "\n",
    "Also I dropped certain rows where the ratings did not make sense or there was no picture provided.\n",
    "\n",
    "Last, I converted the source text into more human read friendly categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
